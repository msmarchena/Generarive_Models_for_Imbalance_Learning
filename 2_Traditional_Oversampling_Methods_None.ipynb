{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Melnvxdx37D"
   },
   "source": [
    "# Analysis using XGB classifier with and without oversampling methods\n",
    "### Author: Marlene Marchena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4MFBwqZx37M",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "#Import visualization libraries\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# over sampling functions\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#set random seed and percentage of test data\n",
    "random_seed = 12345678"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the train and test data saved in the data processing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1 = np.loadtxt('x_train1_outlierTreatment.csv', delimiter=',')\n",
    "y_train1 = np.loadtxt('y_train1_outlierTreatment.csv', dtype='int32', delimiter=',')\n",
    "y_train1 = y_train1.reshape(-1,1)\n",
    "x_test1 = np.loadtxt('x_test_fold1.csv', delimiter=',')\n",
    "y_test1 = np.loadtxt('y_test_fold1.csv', dtype='int32', delimiter=',')\n",
    "y_test1 = y_test1.reshape(-1,1)\n",
    "\n",
    "x_train2 = np.loadtxt('x_train2_outlierTreatment.csv', delimiter=',')\n",
    "y_train2 = np.loadtxt('y_train2_outlierTreatment.csv', dtype='int32', delimiter=',')\n",
    "y_train2 = y_train2.reshape(-1,1)\n",
    "x_test2 = np.loadtxt('x_test_fold2.csv', delimiter=',')\n",
    "y_test2 = np.loadtxt('y_test_fold2.csv', dtype='int32', delimiter=',') \n",
    "y_test2 = y_test2.reshape(-1,1)\n",
    "\n",
    "x_train3 = np.loadtxt('x_train3_outlierTreatment.csv', delimiter=',')\n",
    "y_train3 = np.loadtxt('y_train3_outlierTreatment.csv', dtype='int32', delimiter=',')\n",
    "y_train3 = y_train3.reshape(-1,1)\n",
    "x_test3 = np.loadtxt('x_test_fold3.csv', delimiter=',')\n",
    "y_test3 = np.loadtxt('y_test_fold3.csv', dtype='int32', delimiter=',') \n",
    "y_test3 = y_test3.reshape(-1,1)\n",
    "\n",
    "x_train4 = np.loadtxt('x_train4_outlierTreatment.csv', delimiter=',')\n",
    "y_train4 = np.loadtxt('y_train4_outlierTreatment.csv', dtype='int32', delimiter=',')\n",
    "y_train4 = y_train4.reshape(-1,1)\n",
    "x_test4 = np.loadtxt('x_test_fold4.csv', delimiter=',')\n",
    "y_test4 = np.loadtxt('y_test_fold4.csv', dtype='int32', delimiter=',') \n",
    "y_test4 = y_test4.reshape(-1,1)\n",
    "\n",
    "x_train5 = np.loadtxt('x_train5_outlierTreatment.csv', delimiter=',')\n",
    "y_train5 = np.loadtxt('y_train5_outlierTreatment.csv', dtype='int32', delimiter=',')\n",
    "y_train5 = y_train5.reshape(-1,1)\n",
    "x_test5 = np.loadtxt('x_test_fold5.csv', delimiter=',')\n",
    "y_test5 = np.loadtxt('y_test_fold5.csv', dtype='int32', delimiter=',') \n",
    "y_test5 = y_test5.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the original dataset\n",
    "\n",
    "No oversampling method is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate_Top100(model,x_train,y_train,x_test,y_test):\n",
    "    '''\n",
    "    This fuction fits a model with the original data and evaluate it with the top 100 alerts\n",
    "    model to be used\n",
    "    Returns the confusion matrix and performance measures over the top 100 alerts\n",
    "    '''   \n",
    "    clf = model.fit(x_train,np.ravel(y_train))\n",
    "\n",
    "    # Prediction on the test dataset\n",
    "    predicted = clf.predict(x_test)\n",
    "    pred_prob = clf.predict_proba(x_test) \n",
    "    #selecting only probabilities of frauds\n",
    "    pred_prob1 = pred_prob[:,1]\n",
    "    \n",
    "    #Sorting in descending order by the probability of class 1  \n",
    "    pred_prob_sorted_idx = np.argsort(-pred_prob1)\n",
    "    pred_prob_sorted_idx = pred_prob_sorted_idx[:100]\n",
    "        \n",
    "    y_pred_top100 =predicted[pred_prob_sorted_idx]\n",
    "    y_test_top100 = y_test[pred_prob_sorted_idx]\n",
    "  \n",
    "    f  = round(f1_score(y_test_top100,y_pred_top100),6)  # f1: 2 tp / (2 tp + fp + fn)\n",
    "    recall  = round(recall_score(y_test_top100,y_pred_top100),6) # recall: tp / (tp + fn)\n",
    "    pre  = round(precision_score(y_test_top100,y_pred_top100),6) # precision: tp / (tp + fp)\n",
    "    p, r, _ = precision_recall_curve(y_test_top100,y_pred_top100)\n",
    "\n",
    "    auprc = round(auc(r, p),6) if not np.isnan(auc(r, p)) else None\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_top100,y_pred_top100).ravel()\n",
    "\n",
    "    results = {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp,'precision': pre, 'recall': recall, \n",
    "               'f1_score': f, 'auprc': auprc }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tn': 11, 'fp': 3, 'fn': 9, 'tp': 77, 'precision': 0.9625, 'recall': 0.895349, 'f1_score': 0.927711, 'auprc': 0.973924}, {'tn': 16, 'fp': 4, 'fn': 7, 'tp': 73, 'precision': 0.948052, 'recall': 0.9125, 'f1_score': 0.929936, 'auprc': 0.965276}, {'tn': 20, 'fp': 4, 'fn': 2, 'tp': 74, 'precision': 0.948718, 'recall': 0.973684, 'f1_score': 0.961039, 'auprc': 0.971201}, {'tn': 14, 'fp': 7, 'fn': 8, 'tp': 71, 'precision': 0.910256, 'recall': 0.898734, 'f1_score': 0.904459, 'auprc': 0.944495}, {'tn': 15, 'fp': 6, 'fn': 6, 'tp': 73, 'precision': 0.924051, 'recall': 0.924051, 'f1_score': 0.924051, 'auprc': 0.954051}]\n",
      "        tn  fp  fn  tp  precision    recall  f1_score     auprc\n",
      "fold 1  11   3   9  77   0.962500  0.895349  0.927711  0.973924\n",
      "fold 2  16   4   7  73   0.948052  0.912500  0.929936  0.965276\n",
      "fold 3  20   4   2  74   0.948718  0.973684  0.961039  0.971201\n",
      "fold 4  14   7   8  71   0.910256  0.898734  0.904459  0.944495\n",
      "fold 5  15   6   6  73   0.924051  0.924051  0.924051  0.954051\n",
      "precision    0.938715\n",
      "recall       0.920864\n",
      "f1_score     0.929439\n",
      "auprc        0.961789\n",
      "dtype: float64\n",
      "Time taken = 2.52 minutes\n"
     ]
    }
   ],
   "source": [
    "#Using multiprocessing to speed the running time\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Setting the models to be used\n",
    "    xgb = XGBClassifier(random_state=random_seed)   \n",
    "    \n",
    "    values = ((xgb , x_train1,y_train1,x_test1,y_test1), \n",
    "              (xgb , x_train2,y_train2,x_test2,y_test2), \n",
    "              (xgb , x_train3,y_train3,x_test3,y_test3),   \n",
    "              (xgb , x_train4,y_train4,x_test4,y_test4),   \n",
    "              (xgb , x_train5,y_train5,x_test5,y_test5)   \n",
    "             )   \n",
    "    pool = mp.Pool()\n",
    "    p = pool.starmap(Evaluate_Top100, values)\n",
    "    print(p) \n",
    "    df = pd.DataFrame(p, index =['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'])\n",
    "    print(df)\n",
    "    xgb_df_mean = df.iloc[:,4:].mean()\n",
    "    print(xgb_df_mean)\n",
    "    end = time.time()\n",
    "    total = round(end - start,1)\n",
    "    print('Time taken = {} minutes'.format(total/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Oversampling Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Traditional Oversampling Techniques:\n",
    "* Random Oversampling - ROS\n",
    "* Synthetic Minority Over-sampling Technique - SMOTE\n",
    "* BorderlineSMOTE\n",
    "* ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Oversampling_Evaluate_Top100(model,resample_tech,x_train,y_train,x_test,y_test):\n",
    "    '''\n",
    "    This fuction does an oversampling to balance the training set, then it \n",
    "    fits a model with the balanced data and evaluate the prediction with the top 100 \n",
    "    risky transactions.\n",
    "    model: the model to be used\n",
    "    resample_tech : resample method to be used\n",
    "    Returns the confusion matrix and performance measures over the top 100 alerts\n",
    "    '''   \n",
    "    # Perform resampling\n",
    "    x_over, y_over = resample_tech.fit_resample(x_train,y_train)\n",
    "\n",
    "    clf = model.fit(x_over,np.ravel(y_over))\n",
    "\n",
    "    # Prediction on the test dataset\n",
    "    predicted = clf.predict(x_test)\n",
    "    pred_prob = clf.predict_proba(x_test) \n",
    "    #selecting only probabilities of frauds\n",
    "    pred_prob1 = pred_prob[:,1]\n",
    "    \n",
    "    #Sorting in descending order by the probability of class 1  \n",
    "    pred_prob_sorted_idx = np.argsort(-pred_prob1)\n",
    "    pred_prob_sorted_idx = pred_prob_sorted_idx[:100]\n",
    "        \n",
    "    y_pred_top100 =predicted[pred_prob_sorted_idx]\n",
    "    y_test_top100 = y_test[pred_prob_sorted_idx]\n",
    "  \n",
    "    f  = round(f1_score(y_test_top100,y_pred_top100),6)  # f1: 2 tp / (2 tp + fp + fn)\n",
    "    recall  = round(recall_score(y_test_top100,y_pred_top100),6) # recall: tp / (tp + fn)\n",
    "    pre  = round(precision_score(y_test_top100,y_pred_top100),6) # precision: tp / (tp + fp)\n",
    "    p, r, _ = precision_recall_curve(y_test_top100,y_pred_top100)\n",
    "\n",
    "    auprc = round(auc(r, p),6) if not np.isnan(auc(r, p)) else None\n",
    "\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_top100,y_pred_top100).ravel()\n",
    "\n",
    "    results = {'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp,'precision': pre, 'recall': recall, \n",
    "               'f1_score': f, 'auprc': auprc }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tn': 5, 'fp': 9, 'fn': 0, 'tp': 86, 'precision': 0.905263, 'recall': 1.0, 'f1_score': 0.950276, 'auprc': 0.952632}, {'tn': 14, 'fp': 7, 'fn': 4, 'tp': 75, 'precision': 0.914634, 'recall': 0.949367, 'f1_score': 0.931677, 'auprc': 0.952001}, {'tn': 15, 'fp': 9, 'fn': 1, 'tp': 75, 'precision': 0.892857, 'recall': 0.986842, 'f1_score': 0.9375, 'auprc': 0.94485}, {'tn': 14, 'fp': 8, 'fn': 6, 'tp': 72, 'precision': 0.9, 'recall': 0.923077, 'f1_score': 0.911392, 'auprc': 0.941538}, {'tn': 15, 'fp': 6, 'fn': 2, 'tp': 77, 'precision': 0.927711, 'recall': 0.974684, 'f1_score': 0.950617, 'auprc': 0.961197}]\n",
      "        tn  fp  fn  tp  precision    recall  f1_score     auprc\n",
      "fold 1   5   9   0  86   0.905263  1.000000  0.950276  0.952632\n",
      "fold 2  14   7   4  75   0.914634  0.949367  0.931677  0.952001\n",
      "fold 3  15   9   1  75   0.892857  0.986842  0.937500  0.944850\n",
      "fold 4  14   8   6  72   0.900000  0.923077  0.911392  0.941538\n",
      "fold 5  15   6   2  77   0.927711  0.974684  0.950617  0.961197\n",
      "precision    0.908093\n",
      "recall       0.966794\n",
      "f1_score     0.936292\n",
      "auprc        0.950444\n",
      "dtype: float64\n",
      "Time taken = 5.613333333333333 minutes\n"
     ]
    }
   ],
   "source": [
    "#Using multiprocessing to speed the running time\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Setting the models to be used\n",
    "    ros = RandomOverSampler(random_state=random_seed)\n",
    "    xgb = XGBClassifier(random_state=random_seed) \n",
    "    \n",
    "    values = ((xgb, ros , x_train1,y_train1,x_test1,y_test1), \n",
    "              (xgb, ros , x_train2,y_train2,x_test2,y_test2), \n",
    "              (xgb, ros , x_train3,y_train3,x_test3,y_test3),   \n",
    "              (xgb, ros , x_train4,y_train4,x_test4,y_test4),   \n",
    "              (xgb, ros , x_train5,y_train5,x_test5,y_test5)   \n",
    "             )   \n",
    "    pool = mp.Pool()\n",
    "    p = pool.starmap(Oversampling_Evaluate_Top100, values)\n",
    "    print(p) \n",
    "    df = pd.DataFrame(p, index =['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'])\n",
    "    print(df)\n",
    "    xgb_ros_df_mean = df.iloc[:,4:].mean()\n",
    "    print(xgb_ros_df_mean)\n",
    "    end = time.time()\n",
    "    total = round(end - start,1)\n",
    "    print('Time taken = {} minutes'.format(total/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tn': 0, 'fp': 19, 'fn': 0, 'tp': 81, 'precision': 0.81, 'recall': 1.0, 'f1_score': 0.895028, 'auprc': 0.905}, {'tn': 0, 'fp': 22, 'fn': 0, 'tp': 78, 'precision': 0.78, 'recall': 1.0, 'f1_score': 0.876404, 'auprc': 0.89}, {'tn': 0, 'fp': 26, 'fn': 0, 'tp': 74, 'precision': 0.74, 'recall': 1.0, 'f1_score': 0.850575, 'auprc': 0.87}, {'tn': 0, 'fp': 26, 'fn': 0, 'tp': 74, 'precision': 0.74, 'recall': 1.0, 'f1_score': 0.850575, 'auprc': 0.87}, {'tn': 0, 'fp': 21, 'fn': 0, 'tp': 79, 'precision': 0.79, 'recall': 1.0, 'f1_score': 0.882682, 'auprc': 0.895}]\n",
      "        tn  fp  fn  tp  precision  recall  f1_score  auprc\n",
      "fold 1   0  19   0  81       0.81     1.0  0.895028  0.905\n",
      "fold 2   0  22   0  78       0.78     1.0  0.876404  0.890\n",
      "fold 3   0  26   0  74       0.74     1.0  0.850575  0.870\n",
      "fold 4   0  26   0  74       0.74     1.0  0.850575  0.870\n",
      "fold 5   0  21   0  79       0.79     1.0  0.882682  0.895\n",
      "precision    0.772000\n",
      "recall       1.000000\n",
      "f1_score     0.871053\n",
      "auprc        0.886000\n",
      "dtype: float64\n",
      "Time taken = 7.930000000000001 minutes\n"
     ]
    }
   ],
   "source": [
    "#Using multiprocessing to speed the running time\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Setting the models to be used\n",
    "    sm = SMOTE(random_state=random_seed)\n",
    "    xgb = XGBClassifier(random_state=random_seed) \n",
    "    \n",
    "    values = ((xgb, sm  , x_train1,y_train1,x_test1,y_test1), \n",
    "              (xgb, sm  , x_train2,y_train2,x_test2,y_test2), \n",
    "              (xgb, sm  , x_train3,y_train3,x_test3,y_test3),   \n",
    "              (xgb, sm  , x_train4,y_train4,x_test4,y_test4),   \n",
    "              (xgb, sm  , x_train5,y_train5,x_test5,y_test5)   \n",
    "             )   \n",
    "    pool = mp.Pool()\n",
    "    p = pool.starmap(Oversampling_Evaluate_Top100, values)\n",
    "    print(p) \n",
    "    df = pd.DataFrame(p, index =['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'])\n",
    "    print(df)\n",
    "    xgb_sm_df_mean = df.iloc[:,4:].mean()\n",
    "    print(xgb_sm_df_mean)\n",
    "    end = time.time()\n",
    "    total = round(end - start,1)\n",
    "    print('Time taken = {} minutes'.format(total/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bordeline SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tn': 3, 'fp': 13, 'fn': 0, 'tp': 84, 'precision': 0.865979, 'recall': 1.0, 'f1_score': 0.928177, 'auprc': 0.93299}, {'tn': 7, 'fp': 13, 'fn': 1, 'tp': 79, 'precision': 0.858696, 'recall': 0.9875, 'f1_score': 0.918605, 'auprc': 0.928098}, {'tn': 11, 'fp': 14, 'fn': 0, 'tp': 75, 'precision': 0.842697, 'recall': 1.0, 'f1_score': 0.914634, 'auprc': 0.921348}, {'tn': 12, 'fp': 11, 'fn': 1, 'tp': 76, 'precision': 0.873563, 'recall': 0.987013, 'f1_score': 0.926829, 'auprc': 0.935288}, {'tn': 12, 'fp': 12, 'fn': 1, 'tp': 75, 'precision': 0.862069, 'recall': 0.986842, 'f1_score': 0.920245, 'auprc': 0.929456}]\n",
      "        tn  fp  fn  tp  precision    recall  f1_score     auprc\n",
      "fold 1   3  13   0  84   0.865979  1.000000  0.928177  0.932990\n",
      "fold 2   7  13   1  79   0.858696  0.987500  0.918605  0.928098\n",
      "fold 3  11  14   0  75   0.842697  1.000000  0.914634  0.921348\n",
      "fold 4  12  11   1  76   0.873563  0.987013  0.926829  0.935288\n",
      "fold 5  12  12   1  75   0.862069  0.986842  0.920245  0.929456\n",
      "precision    0.860601\n",
      "recall       0.992271\n",
      "f1_score     0.921698\n",
      "auprc        0.929436\n",
      "dtype: float64\n",
      "Time taken = 7.095 minutes\n"
     ]
    }
   ],
   "source": [
    "#Using multiprocessing to speed the running time\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Setting the models to be used\n",
    "    blSMOTE = BorderlineSMOTE(random_state=random_seed)\n",
    "    xgb = XGBClassifier(random_state=random_seed) \n",
    "    \n",
    "    values = ((xgb, blSMOTE , x_train1,y_train1,x_test1,y_test1), \n",
    "              (xgb, blSMOTE , x_train2,y_train2,x_test2,y_test2), \n",
    "              (xgb, blSMOTE , x_train3,y_train3,x_test3,y_test3),   \n",
    "              (xgb, blSMOTE , x_train4,y_train4,x_test4,y_test4),   \n",
    "              (xgb, blSMOTE , x_train5,y_train5,x_test5,y_test5)   \n",
    "             )   \n",
    "    pool = mp.Pool()\n",
    "    p = pool.starmap(Oversampling_Evaluate_Top100, values)\n",
    "    print(p) \n",
    "    df = pd.DataFrame(p, index =['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'])\n",
    "    print(df)\n",
    "    xgb_blSMOTE_df_mean = df.iloc[:,4:].mean()\n",
    "    print(xgb_blSMOTE_df_mean)\n",
    "    end = time.time()\n",
    "    total = round(end - start,1)\n",
    "    print('Time taken = {} minutes'.format(total/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADASYN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tn': 0, 'fp': 22, 'fn': 0, 'tp': 78, 'precision': 0.78, 'recall': 1.0, 'f1_score': 0.876404, 'auprc': 0.89}, {'tn': 0, 'fp': 22, 'fn': 0, 'tp': 78, 'precision': 0.78, 'recall': 1.0, 'f1_score': 0.876404, 'auprc': 0.89}, {'tn': 0, 'fp': 25, 'fn': 0, 'tp': 75, 'precision': 0.75, 'recall': 1.0, 'f1_score': 0.857143, 'auprc': 0.875}, {'tn': 0, 'fp': 24, 'fn': 0, 'tp': 76, 'precision': 0.76, 'recall': 1.0, 'f1_score': 0.863636, 'auprc': 0.88}, {'tn': 0, 'fp': 25, 'fn': 0, 'tp': 75, 'precision': 0.75, 'recall': 1.0, 'f1_score': 0.857143, 'auprc': 0.875}]\n",
      "        tn  fp  fn  tp  precision  recall  f1_score  auprc\n",
      "fold 1   0  22   0  78       0.78     1.0  0.876404  0.890\n",
      "fold 2   0  22   0  78       0.78     1.0  0.876404  0.890\n",
      "fold 3   0  25   0  75       0.75     1.0  0.857143  0.875\n",
      "fold 4   0  24   0  76       0.76     1.0  0.863636  0.880\n",
      "fold 5   0  25   0  75       0.75     1.0  0.857143  0.875\n",
      "precision    0.764000\n",
      "recall       1.000000\n",
      "f1_score     0.866146\n",
      "auprc        0.882000\n",
      "dtype: float64\n",
      "Time taken = 7.7316666666666665 minutes\n"
     ]
    }
   ],
   "source": [
    "#Using multiprocessing to speed the running time\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    # Setting the models to be used\n",
    "    adasyn = ADASYN(random_state=random_seed)\n",
    "    xgb = XGBClassifier(random_state=random_seed) \n",
    "    \n",
    "    values = ((xgb, adasyn , x_train1,y_train1,x_test1,y_test1), \n",
    "              (xgb, adasyn , x_train2,y_train2,x_test2,y_test2), \n",
    "              (xgb, adasyn , x_train3,y_train3,x_test3,y_test3),   \n",
    "              (xgb, adasyn , x_train4,y_train4,x_test4,y_test4),   \n",
    "              (xgb, adasyn , x_train5,y_train5,x_test5,y_test5)   \n",
    "             )   \n",
    "    pool = mp.Pool()\n",
    "    p = pool.starmap(Oversampling_Evaluate_Top100, values)\n",
    "    print(p) \n",
    "    df = pd.DataFrame(p, index =['fold 1', 'fold 2', 'fold 3', 'fold 4', 'fold 5'])\n",
    "    print(df)\n",
    "    xgb_adasyn_df_mean = df.iloc[:,4:].mean()\n",
    "    print(xgb_adasyn_df_mean)\n",
    "    end = time.time()\n",
    "    total = round(end - start,1)\n",
    "    print('Time taken = {} minutes'.format(total/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Memoire_GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
